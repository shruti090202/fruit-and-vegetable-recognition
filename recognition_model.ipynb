{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XldCCKjCbQpH",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "eOQlRG7ekuQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Iph_dPgU_s-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list with the filepaths for training and testing\n",
        "train_dir = Path('/content/drive/MyDrive/kaggle/input/fruit-and-vegetable-image-recognition/train')\n",
        "train_filepaths = list(train_dir.glob(r'**/*.jpg'))"
      ],
      "metadata": {
        "id": "rTSoqBYWpQW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = Path('/content/drive/MyDrive/kaggle/input/fruit-and-vegetable-image-recognition/test')\n",
        "test_filepaths = list(test_dir.glob(r'**/*.jpg'))"
      ],
      "metadata": {
        "id": "Yuhq8AEWpQZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dir = Path('/content/drive/MyDrive/kaggle/input/fruit-and-vegetable-image-recognition/validation')\n",
        "val_filepaths = list(test_dir.glob(r'**/*.jpg'))"
      ],
      "metadata": {
        "id": "VJGV8Eg5pQbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_processing(filepath):\n",
        "    \"\"\" Create a DataFrame with the filepath and the labels of the pictures\n",
        "    \"\"\"\n",
        "\n",
        "    labels = [str(filepath[i]).split(\"/\")[-2] \\\n",
        "              for i in range(len(filepath))]\n",
        "\n",
        "    filepath = pd.Series(filepath, name='Filepath').astype(str)\n",
        "    labels = pd.Series(labels, name='Label')\n",
        "\n",
        "    # Concatenate filepaths and labels\n",
        "    df = pd.concat([filepath, labels], axis=1)\n",
        "\n",
        "    # Shuffle the DataFrame and reset index\n",
        "    df = df.sample(frac=1).reset_index(drop = True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "EALzi7CtpQdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = image_processing(train_filepaths)\n",
        "test_df = image_processing(test_filepaths)\n",
        "val_df = image_processing(val_filepaths)"
      ],
      "metadata": {
        "id": "8cip_ckepQhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('-- Training set --\\n')\n",
        "print(f'Number of pictures: {train_df.shape[0]}\\n')\n",
        "print(f'Number of different labels: {len(train_df.Label.unique())}\\n')\n",
        "print(f'Labels: {train_df.Label.unique()}')"
      ],
      "metadata": {
        "id": "mYUuuTHspbxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(5)"
      ],
      "metadata": {
        "id": "F4jtAasZpbzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with one Label of each category\n",
        "df_unique = train_df.copy().drop_duplicates(subset=[\"Label\"]).reset_index()\n",
        "\n",
        "# Display some pictures of the dataset\n",
        "fig, axes = plt.subplots(nrows=6, ncols=6, figsize=(8, 7),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(plt.imread(df_unique.Filepath[i]))\n",
        "    ax.set_title(df_unique.Label[i], fontsize = 12)\n",
        "plt.tight_layout(pad=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "krUngr3wpb3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
        ")\n",
        "\n",
        "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
        ")\n"
      ],
      "metadata": {
        "id": "CsKKWkn-phsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=0,\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")"
      ],
      "metadata": {
        "id": "l_Wp5-56phua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=0,\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")"
      ],
      "metadata": {
        "id": "wTyEBB2_phwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "WKiJ7BtPph0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling='avg'\n",
        ")\n",
        "pretrained_model.trainable = False"
      ],
      "metadata": {
        "id": "J4tXUlw5prnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = pretrained_model.input\n",
        "\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(37, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile( optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, validation_data=val_images,batch_size = 32,epochs=5,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=2, restore_best_weights=True)])"
      ],
      "metadata": {
        "id": "ScwpSReSprpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the label of the test_images\n",
        "pred = model.predict(test_images)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "# Map the label\n",
        "labels = (train_images.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "pred1 = [labels[k] for k in pred]\n",
        "pred1"
      ],
      "metadata": {
        "id": "bgolsvyJprrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output(location):\n",
        "    img=load_img(location,target_size=(224,224,3))\n",
        "    img=img_to_array(img)\n",
        "    img=img/255\n",
        "    img=np.expand_dims(img,[0])\n",
        "    answer=model.predict(img)\n",
        "    y_class = answer.argmax(axis=-1)\n",
        "    y = \" \".join(str(x) for x in y_class)\n",
        "    y = int(y)\n",
        "    res = labels[y]\n",
        "    return res"
      ],
      "metadata": {
        "id": "zbhrhrIdpru5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = output('/content/drive/MyDrive/kaggle/input/fruit-and-vegetable-image-recognition/test/corn/Image_5.jpg')\n",
        "img"
      ],
      "metadata": {
        "id": "MYZUVxFxp3or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('recognition.h5')"
      ],
      "metadata": {
        "id": "ruN0xpBrp3vS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}